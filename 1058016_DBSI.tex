\documentclass{article}
\usepackage[left=-1cm, right=2cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{wasysym}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{xmpmulti}
\usepackage{pgfpages}
\usepackage{times}
\usepackage{fullpage}
\usepackage{enumitem}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{automata}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{adjustbox}	
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{lipsum}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\B}{\mathbb{B}}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}

\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%


\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}

% "draft" enables (manual) caching of figures for faster builds

\begin{document}
Departmental Coversheet

Hillary term 2022
Mini-project

Paper title: Database System Implementation

Candidate Number: 1058016

Your degree: MSc Advanced Computer Science

\newpage

\begin{enumerate}
	\item[] To run the code, try make all. There will be an output file RDF\_DB.out. Run the file and you can enter the database interface.  
	\item 
	\begin{enumerate}
	\item 
	The data structure in this paper is a six-column triple table. The subject, predicate, and object of a triple are encoded as integers in the first three columns, $R_s$, $R_p$, and $R_o$, respectively. Conceptually, there are three linked lists, an $sp$-list that connects all triples with the same $R_s$ grouped by $R_p$, an $op$-list that associates all triple with the same $R_o$ grouped by $R_p$, and a $p$-list that relates all triples with the same $R_p$ without any grouping. In the table, the last three columns, $N_{sp}$, $N_{op}$, and $N_p$, store the next-pointes, which are going to be the row numbers in the triple table in the actual implementation.
	
	Apart from the table, six index maps are also maintained. $I_s$, $I_p$, and $I_o$ store the head of the $sp$-list, $p$-list, and $op$-list, respectively. $I_{sp}$ maps $s$ and $p$ to the first occurrence of the triple with the same $s$ and $p$ in the $sp$-list. So does $I_{op}$. $I_{spo}$ stores the row number of each triple in the table. 
	
	\item {\large A}DD(Triple $t$) consists of two parts; first, append a new row to the end of the RDF-index table, and second, associates the new row with all six index maps and alters the pointer columns, $N_{sp}$, $N_{op}$, and $N_p$, to point to the correct row.
	
	Since there is no need to worry about the concurrency in our setting, the RDF-index table is maintained as a fixed size vector of int list of size 6 with each position stands for different columns. Therefore, for each time we add a triple into the table, we simply append it to the last. However, if a triple is already in the $I_{spo}$ map, we skip it. When the size reaches its limit, the entire table will resize. 

\begin{algorithm}[H]
\caption{ADD (t)}\label{alg:cap}
\begin{algorithmic}

\If{$t$ in $I_{spo}$} \Comment{$t = (s, p, o)$ is a triple.}
\State \Return
\EndIf

\State $i$ = \# of elements in the triple-table

\If{$i + 1 > $ the size of the triple-table}
\State resize the triple table
\EndIf
\State $T_{new}$ = $[t.s, t.p, t.o, -1, -1, -1]$ \Comment{The last three columns are left for update later.}
\State triple-table[i] = $T_{new}$
\State $I_{spo}[t] = i$
\State Update remaining indexes
\end{algorithmic}
\end{algorithm}

The columns, $N_{sp}$, $N_{op}$, and $N_p$, are maintained in a linked-list-like manner and are updated simultaneously with the index maps. Take $N_{op}$ for example, if a new triple, $T_{new}$, does not appear in the $I_o$ and $I_{op}$, it means that  $T_{new}$ is a triple with a brand new $T_{new}.s$ and $T_{new}.p$. Therefore, we insert $T_{new}$ into the index map $I_o$ and $I_{op}$ (case1). If we found a $T$ with $T.o = T_{new}.o$ and $T.p = T_{new}.p$, then we insert $T_{new}$ after $T$, and point the next of $T_{new}$ to the original next of the $T$ (case3). A special case is that when there is no next for $T$ and it is handled in case 2 of the Algorithm \eqref{alg:updateIop}. The case of $N_{sp}$ and $N_p$ is similar.

\begin{algorithm}[H]
\caption{Update $I_{op}$($T_{new}$)}\label{alg:updateIop}
\begin{algorithmic}
\State $T$ = the first triple with $T.o = T_{new}.o$ and $T.p = T_{new}.p$
\If{$T$ does not exist}\Comment{Case 1}
\State make $T_{new}$ the head of $I_o$ and $I_{op}$ 
\EndIf

\If{$T$ does not have $T_{next}$}\Comment{Case 2}
\State make $T_{new}$ the head of $I_o$ and $I_{op}$
\State $T_{new}.N_{op} = T$
\EndIf

\If{$T$ has $T_{next}$} \Comment{Case 3}
\State $T_{next} = T.N_{op}$
\State $T_{new}.N_{op} = T_{next}$
\EndIf

\end{algorithmic}
\end{algorithm}

\item 

 
Let $t = \langle s, p, o\rangle$ be a triple pattern and $X$, $Y$, and $Z$ be free variables. There are two inputs for EVALUATE; $t$, the matching pattern, and \textit{index}, the previous row number. There are also two outputs, $t'$, the answer to the match pattern, \textit{index}, the current row number. The index are usually the pointer (row number) to the next triple, but there are two sentinels; \textit{EndOfNode} will tell the caller there is no more next triple to search and \textit{EndSearch} stands for an illegal search. The general framework is shown in Algorithm \eqref{alg:evaluate}.

\begin{algorithm}[H]
\caption{Framework}\label{alg:evaluate}
\begin{algorithmic}

\While{\textit{index} $\neq$ \textit{EndOfNode} and \textit{index} $\neq$ \textit{EndSearch}}
\State \textit{index}, $t' \leftarrow$ Evaluate($t$, \textit{index})
\EndWhile

\end{algorithmic}
\end{algorithm}

Inside EVALUATE, there are four categories, from no free variable to three variables. 

When there is not a free variable, EVALUATE will check if $t$ is in $I_{spo}$ map, if it is return the triple and set the index to be \textit{EndOfNode}. Otherwise, it will return nothing and set the index be \textit{EndSearch}. The pseudo-code is shown in Algorithm \eqref{alg:evaluateSPO}. 

\begin{algorithm}[H]
\caption{Evaluate $\langle s, p, o\rangle$}\label{alg:evaluateSPO}
\begin{algorithmic}
\Require $t = \langle s, p, o\rangle$
\If{$t$ in $I_{spo}$}	
\State \textit{index} $\leftarrow$ \textit{EndOfNode}, $t'\leftarrow t$
\Else
\State \textit{index} $\leftarrow$ \textit{EndSearch}, $t'\leftarrow$ Null
\EndIf
\end{algorithmic}
\end{algorithm}

When there is one free variable, there are three cases: $\langle X, p, o\rangle$, $\langle s, X, o\rangle$, and $\langle s, p, X\rangle$. The first and the last cases are similar. For $\langle X, p, o\rangle$, in the first search, we use the index map, $I_{op}$, to locate the head of the triple with predicate and object the same as $o$ and $p$, then we return the first match and the next pointer at $N_{op}$. For all subsequent evaluates, we traverse $N_{op}$ list until there is not a match. The pseudo-code is suggested in Algorithm \eqref{alg:evaluateXPO}. $\langle s, p, X\rangle$ is similar. 
 
\begin{algorithm}[H]
\caption{Evaluate $\langle X, p, o\rangle$}\label{alg:evaluateXPO}
\begin{algorithmic}
\Require $t = \langle X, p, o\rangle$
\If{hash($t.p, t.o$) does not appear in $I_{op}$}
\State \textit{index} $\leftarrow$ \textit{EndSearch}
\EndIf
\If{it is the first search} \Comment{locate the head}
\State $t'\leftarrow$ the triple $I_{op}$ points to, \textit{index} $\leftarrow$ $t'.N_{op}$.
\Else\Comment{traverse $N_{op}$ list}
\State $t'\leftarrow t.N_{op}$, \textit{index} $\leftarrow t'.N_{op}$
\EndIf
\If{$t'.o$ and $t'.p$ are not we are looking for}\Comment{the end of grouped by.}
\State \textit{index} $\leftarrow$ \textit{EndSearch}
\EndIf
\end{algorithmic}
\end{algorithm}

Since we don't have an index on $s$ and $o$,  $\langle s, X, o\rangle$ needs some extra works. To match this pattern, we can traverse either $sp$-list or $op$-list and skip the triples does not match on $s$ and $o$. The choose of the list depends on the size of $I_s[s]$ and $I_o[o]$ and we use the smaller one. The pseudo-code is in Algorithm \eqref{alg:evaluateSXO}.

\begin{algorithm}[H]
\caption{Evaluate $\langle s, X, o\rangle$}\label{alg:evaluateSXO}
\begin{algorithmic}
\Require $t = \langle s, X, o\rangle$, where $X$ is a special code stands for a free variable. 
\If{$|I_s[s]| < |I_o[o]|$}
\Do
\If{it is the first search}
\State $t'\leftarrow$ the triple $I_{sp}$ points to, \textit{index} $\leftarrow$ $t'.N_{sp}$.
\Else 
\State $t'\leftarrow t.N_{sp}$, \textit{index} $\leftarrow t'.N_{sp}$
\EndIf
\doWhile{$t'.s \neq s$ and $t'.o\neq o$ and \textit{index} $\neq$ \textit{EndOfNode}}
\Else
\Do
\If{it is the first search}
\State $t'\leftarrow$ the triple $I_{op}$ points to, \textit{index} $\leftarrow$ $t'.N_{op}$.
\Else 
\State $t'\leftarrow t.N_{op}$, \textit{index} $\leftarrow t'.N_{op}$
\EndIf
\doWhile{$t'.s \neq s$ and $t'.o\neq o$ and \textit{index} $\neq$ \textit{EndOfNode}}
\EndIf
\If{$t'.s \neq s$ and $t'.o\neq o$}\Comment{corner case}
\State \textit{index} = \textit{EndSearch}
\EndIf 
\end{algorithmic}
\end{algorithm}


When there are two free variables, there are also three cases: $\langle X, Y, o\rangle$, $\langle X, p, Z\rangle$, and $\langle s, Y, Z\rangle$, where $X$, $Y$, and $Z$ can be equal. Their ideas are similar; $\langle X, Y, o\rangle$, for example, we first find $I_o[t.o]$ and traverse the $op$-list till the end. If $X=Y$, then we skip those triples with $p \neq o$. The pseudo-code is given in Algorithm \eqref{alg:evaluateXYO}\footnote{Even I found myself a little confused by what I wrote in the do-while loop, so this footnote might be helpful. After a few minutes of thinking, I found only when we want $X=Y$, the condition $t'.p \neq t'.s$ will make the loop start and try to locate the one with $t.p = t.s$. If $X\neq Y$, the loop will never start and return immediately.}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, Y, o\rangle$}\label{alg:evaluateXYO}
\begin{algorithmic}
\Require $t = \langle X, Y, o\rangle$, where $X$ and $Y$ are special codes stand for variables. 
\Do
\If{it is the first search}
\State $t'\leftarrow$ the triple $I_{o}$ points to, \textit{index} $\leftarrow$ $t'.N_{op}$.
\Else 
\State $t'\leftarrow t.N_{op}$, \textit{index} $\leftarrow t'.N_{op}$
\EndIf
\doWhile{$X= Y$ and $t'.p \neq t'.s$ and \textit{index} $\neq$ \textit{EndOfNode}}
\If{$X=Y$ and $t'.p\neq t'.s$}\Comment{stop traversing when $t'.p\neq t'.s$ when the pattern asks $X=Y$}
\State \textit{index} = \textit{EndSearch}
\EndIf
\end{algorithmic}
\end{algorithm}
The ideas for the other two patterns are similar; start from $I_p$ or $I_s$ map and traverse the $p$-list or $sp$-list.

When there are three free variables, the paper suggests to match, for example, the patterns like $\langle X, Y, Z\rangle$, we need to iterate over the triple table; if we want $X = Y$,  we skip those $X\neq Y$. However, this is not efficient. Therefore, I modified a little bit and the idea and pseudo-code are discussed in 2.a, where I put everything that is different from the paper there. 

\end{enumerate}
\item 
\begin{enumerate}
\item RDF indexing data structure that implements Add and Evaluate functions.

This component is included in RDF\_index.cpp, in which ADD and EVALUATE are implemented as suggested in the problem 1. There are a few things that is slightly different from the paper. 

1) I used XXHASH\footnote{https://cyan4973.github.io/xxHash/} by Facebook instead of Jenkings hashing, because it achieves state-of-the-art excellent performance on both long and small inputs. Jenkings hashing is implemented in RDF\_index.h and but it is commented. I did some tests and observed that Jenkings is about 4\% slower than XXHASH in average\footnote{For loading, XXHASH and Jenkings took 314.359, 4026.82, and 323.914, 4206.85, and 58582.4 ms on three datasets, respectively, achieving 2\%, 4\%, and 8\% speed up on each.}. 

2) Instead of open addressing, I eventually choose std::unordered\_map for index maps $I_{sp}$, $I_{op}$ and $I_{spo}$. I had an open addressing hash implemented in HashTable.cpp and HashTable.h (attached in the submission), but it was much slower than the unordered\_map by about 20\% or more.

3) To match the patterns like $\langle X, Y, Z\rangle$, the paper suggests to iterate over the triple table; if we want $X = Y$,  we skip those $X\neq Y$. I modify this a little bit to improve the efficiency. Again, $\langle X, X, Z\rangle$, for example, we first iterate $I_s$, and for each $s$ in $I_s$, we find if $I_{sp}$ includes hash($s, s$), if yes, we traverse over the triple table. As shown in the pseudo-code in Algorithm \eqref{alg:evaluateXXP}\footnote{The actual implementation is slightly different. I put the check of if $i$ in $I_{sp}$ at the beginning of the Evaluate\_SPZ to reduce some code redundancy, but they are equivalent.}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, X, Z\rangle$}\label{alg:evaluateXXP}
\begin{algorithmic}
\For{$s$ in $I_s$}
\State $i = $ hash($s, s$)
\If{$i$ in $I_{sp}$}	
\State Evaluate\_SPZ($s, s$)
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

$\langle X, Y, Y\rangle$ and $\langle X, Y, X\rangle$ are similar. For $\langle X, X, X\rangle$, we only need to traverse  $s$ in $I_s$ and find if $\langle s, s, s\rangle$ is in $I_{spo}$ as shown in  Algorithm \eqref{alg:evaluateXXX}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, X, X\rangle$}\label{alg:evaluateXXX}
\begin{algorithmic}
\For{$s$ in $I_s$}
\State Evaluate\_SPO($s, s, s$) 
\EndFor
\end{algorithmic}
\end{algorithm}

\item The engine for evaluating BGP SPARQL queries.

This part is in the file SPARQL\_engine.cpp and it is implemented strictly based on the model answer. A few additional lines are added for printing or improving performance.

\item The greedy join order optimization query planner.

This part can be sought in the file query\_planner.cpp. I see what the model answer is trying to say, but I believe there are some minor mistakes, so I made some slight changes, but it is still $O(n^2)$, where $n$ is the number of triple patterns we try to fit. There were four things I modified. 

Firstly, the last three lines should go to the outside while loop. 


Secondly, I changed the criteria for updating the new triple patterns. In the model answer, the criteria is 

\begin{equation}\label{criteria}
	t_{best} = \perp \text{ or } score < score_{best} \text{ and either } var(t) = \emptyset \text{ or } var(t) \cap B \neq \emptyset.
\end{equation}

It is troublesome because it will always take the first unprocessed triple pattern as the best pattern and compare this with the remaining. However, it might cause some issues in many cases. For example, the following triple patterns 
\begin{align*}
	\langle X &,\quad 1,\quad 2\rangle \\
	\langle Y &,\quad 2,\quad 3\rangle\\
	\langle X &,\quad 4,\quad Y\rangle
\end{align*}
will produce the plan $\langle X, 1, 2\rangle \mapsto \langle Y, 2, 3\rangle \mapsto \langle X, 4, Y\rangle$ because even after we replace the $X$ in $\langle X, 4, Y\rangle$, this triple pattern still has a higher selectivity than $\langle Y, 2, 3\rangle$. Therefore, this plan will create an unnecessary cross product, and I believe the criteria \eqref{criteria} meant choosing the triple pattern that has the lowest selectivity and includes some variables that are in the processed patterns. Thus, I made some modifications to the algorithm, and it will 1) as long as an unprocessed pattern has a variable that is processed, we will always consider this pattern and 2) if this pattern has lower selectivity than the previous one, we choose this pattern as the best triple. With this modification, the plan becomes $\langle X, 1, 2\rangle \mapsto \langle X, 4, Y\rangle \mapsto \langle Y, 2, 3\rangle$. 

Thirdly, there are some cases that $|\langle X, 1, 2\rangle| = 10,000$ but $|\langle Y, 2, 3\rangle| = 10$. If we ignore the size of the pattern, we might produce a lot of unnecessary joins, but we can store this information while we are updating $I_{op}$. Therefore, I also record the size of $I_{op}[op]$ and $I_{sp}[sp]$, and we choose the best triple pattern based on both selectivity and size. Our final query plan is $\langle Y, 2, 3\rangle \mapsto \langle X, 4, Y\rangle \mapsto \langle X, 1, 2\rangle$, which is the most optimal plan. Notice that only $I_{op}$ and $I_{sp}$ are considered because they are the most common cases, and recording the size of other index maps would produce overhead in indexing. Since the size of $I_{op}[t]$ and $I_{sp}[t]$ can be recored while we are inserting triple, the cost of maintaining the size is negligible\footnote{There are many tricks to save memory. For example, let's say $I_{sp}$ is an unordered\_map$<$int, int$>$, where the first int is the hash key and the second int is the index of row number. For a table size smaller than $2^{24}$ rows, we can use the higher $7$ bits to store the size and lower 24 bits to store the index. Other trick might apply also.}. 

Lastly, the original query plan was based on the following precedence relation $\prec$ on selectivity of triple patterns: 
\begin{equation*}
	(s, p, o) \prec (s, ?, o) \prec (?, p, o) \prec (s, p, ?) \prec (?, ?, o) \prec (s, ?, ?) \prec (?, p, ?) \prec (?, ?, ?).
\end{equation*}
Now, since we have maintained the size of $(?, p, o)$ and $(s, p, ?)$, a new order of the selectivity should be used:
\begin{equation*}
	(s, p, o) \prec (s, ?, o) \prec (?, p, o) = (s, p, ?) \prec (?, ?, o) \prec (s, ?, ?) \prec (?, p, ?) \prec (?, ?, ?).
\end{equation*}
Therefore, when we are precessing these two patterns, instead of comparing the selectivity, we can directly compare the actual size of the triple patterns and select the smaller one. For example, for the following triple patterns,
\begin{align*}
	\langle X,\quad 1,\quad 2\rangle \\
	\langle 2,\quad 3,\quad Y\rangle
\end{align*}
with $|\langle 2, 3, Y\rangle| > |\langle X, 1, 2\rangle|$ will produce the following query plan,
\begin{align*}
	\langle 2,\quad 3,\quad Y\rangle\\
	\langle X,\quad 1,\quad 2\rangle
\end{align*}

The pseudo-code goes as the following. 

\begin{algorithm}[H]
\caption{New-Plan-Query($U$)}\label{alg:greedy}
\begin{algorithmic}

\State $P \leftarrow []$, $B\leftarrow \emptyset$
\While{$U\neq \emptyset$}
\State $t_{best}\leftarrow \perp$, $score_{beset} \leftarrow 100$, intersected $\leftarrow$ false
\For{\textbf{each} unprocessed tripple pattern $t\in U$}
\State $score \leftarrow$ the position of $t$ in $\prec$ where the variables in $B$ are considered bounded
\If{$t_{best} = \perp$}
\State intersected = ($var(t) \cap B \neq \emptyset$)
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$
\EndIf
\If{$t$ and $t_{best}$ are of the form $\langle X, p, o\rangle$ or $\langle s, p, X\rangle$}
\State $t_{best}\leftarrow$ the one with a smaller size
\EndIf
\If{intersected}
\If{$score < score_{best}$ and either $var(t) = \emptyset$ or $var(t) \cap B \neq \emptyset$}
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$
\EndIf
\Else
\If{$var(t) = \emptyset$ or $var(t) \cap B \neq \emptyset$} \Comment{make sure that the next pattern share some variables.}
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$, intersected $\leftarrow$ true
\EndIf
\EndIf

\EndFor
\EndWhile

\end{algorithmic}
\end{algorithm}


From Table 1, we see a significant improvement in most of the queries. The testing protocol is the same as the one in question 3. To do the test, uncomment lines 20-25 in query\_planner.cpp and comment lines 26-53 and MAKE TEST. The analysis of the result is included in 3.c.

\begin{table}[]\centering
\begin{tabular}{|l|l|l|l|}
\hline
	& Model Answer (ms) & New Query Plan (ms) & Improvement (\%) \\ \hline
q1  & 0.2269            & 0.0038              & 5971.05263       \\ \hline
q2  & 370.891           & 0.8707              & 42596.8761       \\ \hline
q3  & 1.289             & 0.0022              & 58590.9091       \\ \hline
q4  & 0.1669            & 0.0241              & 692.53112        \\ \hline
q5  & 2.2444            & 0.06                & 3740.66667       \\ \hline
q6  & 0.3               & 0.2121              & 141.442716       \\ \hline
q7  & 2716.41           & 0.0106              & 25626509.4       \\ \hline
q8  & 28.3936           & 1.6634              & 1706.96164       \\ \hline
q9  & 1033.41           & 1.1611              & 89002.6699       \\ \hline
q10 & 2.3399            & 0.0018              & 129994.444       \\ \hline
q11 & 0.0617            & 0.0205              & 300.97561        \\ \hline
q12 & 0.0517            & 0.0105              & 492.380952       \\ \hline
q13 & 1.3423            & 0.0018              & 74572.2222       \\ \hline
q14 & 0.2384            & 0.1947              & 122.444787       \\ \hline
\end{tabular}
\caption{Time took to process and evaluate the query by the model answer and the new query plan in ms on the dataset LUBM-001-mat.ttl. The new plan achieves more than 1,859,602.501\% speed up in average on the 14 queries.}
\end{table}

\item The component for parsing and importing Turtle files.

This part is included in Turtle\_handler.cpp. 

\item The parser for SPARQL queries

This part is included in query\_parser.cpp. 

\item The component implementing the command line

This part is included in interface.cpp.

\end{enumerate}
\newpage
\item[3.a]
\begin{enumerate}
\item Hardware and Software Configuration:

\begin{enumerate}
\item Model Identifier:	MacBookPro14,3

\item Processor Name:	Apple M1 Pro

\item Processor Speed:	3.2 GHz

\item Number of Processors:	1

\item Total Number of Cores:	10

\item Memory:	32 GB

\item Operating System: macOS Monterey, Version 12.3

\item Compiler Version: Apple clang version 13.1.6 (clang-1316.0.21.2)

\end{enumerate}

\item 

We set a timeout if one instruction takes more than 3 minutes. The following protocol can be found in protocol.cpp. If you want to run the load test, fill in the correct path to the data and uncomment some lines. It will take about 15 minutes to run. 

Loading Data Test Protocol:

\begin{enumerate}
\item *Restart computer* and turn off all irrelevant applications.
\item Start a clean terminal.
\item Load dataset 001 and markdown the time. If timeout, mark TO. 
\item Delete all objects.
\item Load dataset 010 and markdown the time. If timeout, mark TO. 
\item Delete all objects.
\item Load dataset 100 and markdown the time. If timeout, mark TO. 
\item Delete all objects.
\item Go back to step ii repeat this process for 10 times.
\item Take the average. 
\end{enumerate}
To eliminate the cache effect, I load 3 datasets one by one for 10 times instead of running a single dataset for 10 times. This will flush most of caches. Also, I should play my phone and don't touch my laptop while running.

\item 
We choose COUNT instead of SELECT and for each query. We set a timeout if one instruction takes more than 3 minutes. 


Loading Data Test Protocol:

\begin{enumerate}
\item *Restart computer* and turn off all irrelevant applications.
\item Start a clean terminal.
\item MAKE all and run the output file.
\item Load one dataset. 
\item Run 14 queries one by one and markdown the time. 
\item Go back to the step v and  repeat 10 times. 
\item Take the average. 
\end{enumerate}

To avoid the cache effect, I run 14 queries one by one for 10 times instead of running a single queries for 10 times.

\end{enumerate}

\item[3.b] The time needed to load and index the data and the time needed to produce all query answers for each RDF graph and query are showed in Table 2 and Table 3, respectively.

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|}
\hline
                   & LUBM-001-mat (ms) & LUBM-010-mat (ms) & LUBM-100-mat (ms)\\ \hline
Load \& Index Time & 114.651          & 2058.07        & 25624.2        \\ \hline
\end{tabular}
\caption{Time needed to load and index the data in ms.}
\end{table}


\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|}
\hline
	& LUBM-001-mat (ms) & LUBM-010-mat (ms) & LUBM-100-mat (ms) \\ \hline
q1  & 0.0038            & 0.0063            & 0.0371            \\ \hline
q2  & 0.8707            & 31.8538           & 348.732           \\ \hline
q3  & 0.0022            & 0.008             & 0.012             \\ \hline
q4  & 0.0241            & 0.0599            & 0.0932            \\ \hline
q5  & 0.06              & 0.1908            & 0.2434            \\ \hline
q6  & 0.2121            & 11.3648           & 253.683           \\ \hline
q7  & 0.0106            & 0.0314            & 0.1369            \\ \hline
q8  & 1.6634            & 4.153             & 9.8969            \\ \hline
q9  & 1.1611            & 42.0941           & 981.896           \\ \hline
q10 & 0.0018            & 0.0058            & 0.0163            \\ \hline
q11 & 0.0205            & 0.0599            & 0.1568            \\ \hline
q12 & 0.0105            & 0.2159            & 0.4706            \\ \hline
q13 & 0.0018            & 0.01              & 0.2973            \\ \hline
q14 & 0.1947            & 8.8916            & 272.475           \\ \hline
\end{tabular}
\caption{Time needed to produce  all query answers in ms.}
\end{table}

\item[3.c]
\begin{enumerate}
\item[q1:] This query consists of two triple patterns, and they are both in the form of $\langle X, p, o\rangle$. My query plan picks the second one as a start because it is considerably smaller (1874 v.s. 4). Otherwise, it will be very slow, as Table 1 suggested. 

\item[q2:] This query contains two groups of the forms $\langle X, p, o\rangle$, and $\langle X, p, Z\rangle$, and each group has three triples. The plan is to find a $\langle X, p, o\rangle$, then a $\langle X, p, Z\rangle$ that matches the first pick, and pick whatever matches the variable, $Z$, in the remaining unprocessed patterns. It picks not only the least selectivity pattern but also the smallest pattern in each step, resulting in a very short running time (compared to the model solution in Table 1). 
\item[q3:] This one is similar to q1, but they have different sizes in each pattern. In LUBM-001-mat.ttl, q3 has 5999 possible matches in the first pattern and 6 in the second; q1 has 1874 in the first and 4 in the second. Therefore, q3 is slightly slower than q1. 
\item[q4:] Though this query looks terrifying, the speed is fast because all patterns share the same $X$ in $p$, and besides this, there is at most one free variable in each. Therefore, once $X$ with the smallest size is picked, the remaining is just to check if a $Y$ can go with the $X$. 
\item[q5:] This one is similar to q1 and q3 but is much slower because the search space is large. This one has 8330 possibilities for the first pattern and  719 for the second, so even starting from the second one would slow down by a lot. 
\item[q6:] This query simply matches just one pattern. No plan is needed. From the smallest to the largest dataset, the result sizes are 7790, 99566, and 1048532. So the time increases as we expected.
\item[q7:] There are two triples like $\langle X, p, o\rangle$. Since the first one has the size 7790 and the second one is 1627, starting at the second one, the performance is much better (see Table 1). 
\item[q8:] All three datasets produce 7790 results, so the time is about the same. It also illustrate that we have an excellent query plan because pattern 1 has 7790 matches in the smallest dataset but 1048532 matches in the largest dataset. However, pattern 3 has 239 possible matches among all datasets. Therefore, by choosing pattern 3 as a start, we ensure that the time does not change as the size of pattern 1 changes. 
\item[q9:] It is like q8, but the sizes of the first three patterns increase by ~12x from the smallest dataset to the largest. Therefore, even if we pick the smallest parttern to start with, the time will still increase. 
\item[q10:] Same as q1 and q3. 
\item[q11:] Like q10, the performance of q1, q3, q10, and q11 are good because they choose the pattern with the smallest size to start.
\item[q12:] It is almost like q11. It first finds the smallest of the form $\langle X, p, o\rangle$ and matches $\langle X, p, Y\rangle$. Then all others are just $\langle s, p, o\rangle$ and can be verified very quickly. 
\item[q13:] There are 8330 choices for the first pattern but just one for the second. If we do it in order, it will be slow. However, the plan first takes $\langle s, p, X\rangle$ and then $\langle X, p, o\rangle$ because they have the same selectivity but different in sizes.
\item[q14:] Same as q6. The running time increases as the size increases. 
\end{enumerate}
\end{enumerate}













\end{document}