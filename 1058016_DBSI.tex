\documentclass{article}
\usepackage[left=-1cm, right=2cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{wasysym}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage{latexsym}
\usepackage{xmpmulti}
\usepackage{pgfpages}
\usepackage{times}
\usepackage{fullpage}
\usepackage{enumitem}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{automata}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{adjustbox}	
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{lipsum}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\B}{\mathbb{B}}
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{blindtext}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}

\algdef{SE}[DOWHILE]{Do}{doWhile}{\algorithmicdo}[1]{\algorithmicwhile\ #1}%


\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}[theorem]{Example}

% "draft" enables (manual) caching of figures for faster builds

\begin{document}
Departmental Coversheet

Hillary term 2022
Mini-project

Paper title: Database System Implementation

Candidate Number: 1058016

Your degree: MSc Advanced Computer Science

\newpage

\begin{enumerate}
	\item 
	\begin{enumerate}
	\item 
	The data structure in this paper is a six-column triple table. The subject, predicate, and object of a triple are encoded as integers in the first three columns, $R_s$, $R_p$, and $R_o$, respectively. Conceptually, there are three linked lists, an $sp$-list that connects all triples with the same $R_s$ grouped by $R_p$, an $op$-list that associates all triple with the same $R_o$ grouped by $R_p$, and a $p$-list that relates all triples with the same $R_p$ without any grouping. In the table, the last three columns, $N_{sp}$, $N_{op}$, and $N_p$, store the next-pointes, which are going to be the row number in the triple table in the actual implementation.
	
	Six index maps are also maintained. $I_s$, $I_p$, and $I_o$ store the head of the $sp$-list, $p$-list, and $op$-list, respectively. $I_{sp}$ maps $s$ and $p$ to the first occurrence of the triple with the same $s$ and $p$ in the $sp$-list. So does $I_{op}$. $I_{spo}$ stores the row number of each triple in the table. 
	
	\item {\large A}DD(Triple $t$) consists of two parts; first, append a new row to the end of the RDF-index table, and second, associates the new row with all six index maps and alter the pointer columns, $N_{sp}$, $N_{op}$, and $N_p$, to point to the correct row.
	
	Since there is no need to worry about the concurrency in our setting, the RDF-index table is maintained as a fixed size vector of int list of size 6 with each position stands for different columns. Therefore, for each time we add a triple into the table, we simply append it to the last. However, if the triple is already in the $I_{spo}$ map, we skip it. When the size reaches its limit, the entire table will resize. 

\begin{algorithm}[H]
\caption{ADD (t)}\label{alg:cap}
\begin{algorithmic}

\If{$t$ in $I_{spo}$} \Comment{$t = (s, p, o)$ is a triple.}
\State \Return
\EndIf

\State $i$ = \# of elements in the triple-table

\If{$i + 1 > $ the size of the triple-table}
\State resize the triple table
\EndIf
\State $T_{new}$ = $[t.s, t.p, t.o, -1, -1, -1]$ \Comment{The last three columns are left for update later.}
\State triple-table[i] = $T_{new}$
\State $I_{spo}[t] = i$
\State Update remaining indexes
\end{algorithmic}
\end{algorithm}

The columns, $N_{sp}$, $N_{op}$, and $N_p$, are maintained in a linked-list-like manner and are updated simultaneously with the index maps. Take $N_{op}$ for example, if $T_{new}$ does not appear in the $I_o$ and $I_{op}$, it means that  $T_{new}$ is a new triple that the triple table never see before. Therefore, we insert $T_{new}$ into the index map $I_o$ and $I_{op}$ (case1). If we found a $T$ with $T.o = T_{new}.o$ and $T.o = T_{new}.p$, then we insert $T_{new}$ after $T$, and point the next of $T_{new}$ to the original next of the $T$ (case3). A special case is that when there is no next for $T$ and it is handled in case 2 of the Algorithm \eqref{alg:updateIop}. The case of $N_{sp}$ and $N_p$ is similar.

\begin{algorithm}[H]
\caption{Update $I_{op}$($T_{new}$)}\label{alg:updateIop}
\begin{algorithmic}
\State $T$ = the first triple with $T.o = T_{new}.o$ and $T.o = T_{new}.p$
\If{$T$ does not exist}\Comment{Case 1}
\State make $T_{new}$ the head of $I_o$ and $I_{op}$ 
\EndIf

\If{$T$ does not have $T_{next}$}\Comment{Case 2}
\State make $T_{new}$ the head of $I_o$ and $I_{op}$
\State $T_{new}.N_{op} = T$
\EndIf

\If{$T$ has $T_{next}$} \Comment{Case 3}
\State $T_{next} = T.N_{op}$
\State $T_{new}.N_{op} = T_{next}$
\EndIf

\end{algorithmic}
\end{algorithm}

\item 

 
Let $t = \langle s, p, o\rangle$ be a triple pattern and $X$, $Y$, and $Z$ be free variables. There are two inputs for EVALUATE; $t$, the matching pattern, and \textit{index}, the previous state. There are also two outputs, $t'$, the answer to the math pattern, \textit{index}, the current state. The index are usually the pointer to the next triple, but there are two sentinel; \textit{EndOfNode} will tell the caller there is no more next triple to search and \textit{EndSearch} stands for an illegal search. The general frame work is shown in Algorithm \eqref{alg:evaluate}.

\begin{algorithm}[H]
\caption{Framework}\label{alg:evaluate}
\begin{algorithmic}

\While{\textit{index} $\neq$ \textit{EndOfNode} and \textit{index} $\neq$ \textit{EndSearch}}
\State \textit{index}, $t' \leftarrow$ Evaluate($t$, \textit{index})
\EndWhile

\end{algorithmic}
\end{algorithm}

Inside EVALUATE, there are four categories we need to discuss, from no free variable to all three are variables. 

When there is not free variable, EVALUATE will check if $t$ is in $I_{spo}$ map, if it is return the triple and set the index be \textit{EndOfNode}. Otherwise, it will return nothing and set the index be \textit{EndSearch}. The pseudo-code is shown in Algorithm \eqref{alg:evaluateSPO}. 

\begin{algorithm}[H]
\caption{Evaluate $\langle s, p, o\rangle$}\label{alg:evaluateSPO}
\begin{algorithmic}
\Require $t = \langle s, p, o\rangle$
\If{$t$ in $I_{spo}$}	
\State \textit{index} $\leftarrow$ \textit{EndOfNode}
\State \Return t
\Else
\State \textit{index} $\leftarrow$ \textit{EndSearch} 
\EndIf
\end{algorithmic}
\end{algorithm}

When there is one free variable, there are three cases: $\langle X, p, o\rangle$, $\langle s, X, o\rangle$, and $\langle s, p, X\rangle$. The first and the last cases are similar. For $\langle X, p, o\rangle$, in the first search, we use the index map, $I_{op}$, to locate the head of the triple with predicate and object the same as $o$ and $p$, then we return the first match and the next pointer at $N_{op}$. For all subsequent evaluate, we traverse $N_{op}$ list until there is no match. The pseudo-code is suggested in Algorithm \eqref{alg:evaluateXPO}.
 
\begin{algorithm}[H]
\caption{Evaluate $\langle X, p, o\rangle$}\label{alg:evaluateXPO}
\begin{algorithmic}
\Require $t = \langle X, p, o\rangle$
\If{hash($t.p, t.o$) does not appear in $I_{op}$}
\State \textit{index} $\leftarrow$ \textit{EndSearch}
\EndIf
\If{it is the first search} \Comment{locate the head}
\State $t'\leftarrow$ the triple $I_{op}$ points to, \textit{index} $\leftarrow$ $t'.N_{op}$.
\Else\Comment{traverse $N_{op}$ list}
\State $t'\leftarrow t.N_{op}$, \textit{index} $\leftarrow t'.N_{op}$
\EndIf
\If{$t'.o$ and $t'.p$ are not we are looking for}\Comment{the end of grouped by.}
\State \textit{index} $\leftarrow$ \textit{EndSearch}
\EndIf
\end{algorithmic}
\end{algorithm}

$\langle s, p, X\rangle$ is similar. Since we don't have index on $s$ and $o$,  $\langle s, X, o\rangle$ needs some extra works. Assume that the size of the $I_s$ is smaller than that of $I_o$, then for each matching pattern $t$, we iterate over $s$ in $I_s$, 


When there are two free variables, there are also three cases: $\langle X, Y, o\rangle$, $\langle X, p, Z\rangle$, and $\langle s, Y, Z\rangle$, where $X$, $Y$, and $Z$ can be equal. Their idea is similar; $\langle X, Y, o\rangle$, for example, we first find $I_o[t.o]$ and traverse the $op$-list till the end. If $X=Y$, then we skip those triples with $p \neq o$. The pseudo-code is given in Algorithm \eqref{alg:evaluateXYO}\footnote{Even I found myself a little confused by what I wrote in the do-while loop, so this footnote might be helpful. After a few minutes of thinking, I found only when we want $X=Y$, the condition $t'.p \neq t'.s$ will make the loop start and try to locate the one with $t.p = t.s$. If $X\neq Y$, the loop will never start and return immediately.}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, Y, o\rangle$}\label{alg:evaluateXYO}
\begin{algorithmic}
\Require $t = \langle X, Y, o\rangle$, where $X$ and $Y$ are special code stands for variables. 
\Do
\If{it is the first search}
\State $t'\leftarrow$ the triple $I_{o}$ points to, \textit{index} $\leftarrow$ $t'.N_{op}$.
\Else 
\State $t'\leftarrow t.N_{op}$, \textit{index} $\leftarrow t'.N_{op}$
\EndIf
\doWhile{$X= Y$ and $t'.p \neq t'.s$ and \textit{index} $\neq$ \textit{EndOfNode}}
\If{$X=Y$ and $t'.p\neq t'.s$}\Comment{stop traversing when $t'.p\neq t'.s$ when the pattern asks $X=Y$}
\State \textit{index} = \textit{EndSearch}
\EndIf
\end{algorithmic}
\end{algorithm}
The idea for the other two patterns are similar, but starts from $I_p$ or $I_s$ map and traverse the $p$-list or $sp$-list.

When there are three free variables, the paper suggests to match, for example, the patterns like $\langle X, Y, Z\rangle$, we need to iterate over the triple table; if we want $X = Y$,  we skip those $X\neq Y$. However, this is not efficient. Therefore, I modified a little bit and the idea and pseudo-code are discussed in 2.a, where I put everything that is different from paper there. 

\end{enumerate}
\item 
\begin{enumerate}
\item RDF indexing data structure that implements Add and Evaluate functions.

This component is included in RDF\_index.cpp, in which ADD and EVALUATE are implemented as suggested in the problem 1. There are a few things that is slightly different from the paper. 

1) I used XXHASH\footnote{https://cyan4973.github.io/xxHash/} by Facebook instead of Jenkings hashing, because it achieves state-of-the-art excellent performance on both long and small inputs. 

2) Instead of open addressing, I eventually choose std::unordered\_map for index maps $I_{sp}$, $I_{op}$ and $I_{spo}$. I had an open addressing hash implemented in HashTable.cpp and HashTable.h (attached in the submission), but it was much slower than the unordered\_map (by about 20\% or more).

3) To match the patterns like $\langle X, Y, Z\rangle$, the paper suggests to iterate over the triple table; if we want $X = Y$,  we skip those $X\neq Y$. I modify this a little bit to improve the efficiency. Again, $\langle X, X, Z\rangle$, for example, we first iterate $I_s$, and for each $s$ in $I_s$, we find if $I_{sp}$ includes hash($s, s$), if yes, we traverse over the triple table. As shown in the pseudo-code in Algorithm \eqref{alg:evaluateXXP}\footnote{The actual implementation is slightly different. I put the check of if $i$ in $I_{sp}$ at the begging of the Evaluate\_SPZ to reduce some code redundancy, but they are equivalent.}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, X, Z\rangle$}\label{alg:evaluateXXP}
\begin{algorithmic}
\For{$s$ in $I_s$}
\State $i = $ hash($s, s$)
\If{$i$ in $I_{sp}$}	
\State Evaluate\_SPZ($s, s$)
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

$\langle X, Y, Y\rangle$ and $\langle X, Y, X\rangle$ are similar. For $\langle X, X, X\rangle$, we only need to traverse  $s$ in $I_s$ and find if $\langle s, s, s\rangle$ is in $I_{spo}$ as shown in  Algorithm \eqref{alg:evaluateXXX}.

\begin{algorithm}[H]
\caption{Evaluate $\langle X, X, X\rangle$}\label{alg:evaluateXXX}
\begin{algorithmic}
\For{$s$ in $I_s$}
\State Evaluate\_SPO($s, s, s$) 
\EndFor
\end{algorithmic}
\end{algorithm}

\item The engine for evaluating BGP SPARQL queries.

This part is in the file SPARQL\_engine.cpp and it is implemented strictly based on the model answer. A few additional lines are added for printing or improving performance.

\item The greedy join order optimization query planner.

This part can be sought in the file query\_planner.cpp. I see what the model answer is trying to say but I believe there are some minor mistakes so I change it slightly but it is still $O(n)$, where $n$ is the number of triple patterns we try to fit. 

There were two things I modified. Firstly, the last three lines should go to the outside while loop. Secondly and most importantly, I changed the criteria for updating the new triple patterns. In the model answer, the criteria is 
\begin{equation}\label{criteria}
	t_{best} = \perp \text{ or } score < score_{best} \text{ and either } var(t) = \emptyset \text{ or } var(t) \cap B \neq \emptyset.
\end{equation}
It is troublesome because it will always take the first unprocessed triple pattern as the best pattern and compare this with the remaining. However, it might cause some issues in many cases. For example, the following triple patterns 
\begin{align*}
	\langle X &,\quad 1,\quad 2\rangle \\
	\langle Y &,\quad 2,\quad 3\rangle\\
	\langle X &,\quad 4,\quad Y\rangle
\end{align*}
will produce the plan $\langle X, 1, 2\rangle \mapsto \langle Y, 2, 3\rangle \mapsto \langle X, 4, Y\rangle$ because even after we replace the $X$ in $\langle X, 4, Y\rangle$, this triple pattern still has higher selectivity than $\langle Y, 2, 3\rangle$. However, this plan will create an unnecessary cross product and I believe the criteria \eqref{criteria} meant choosing the triple pattern that has the lowest selectivity and includes some variables that are in the  processed patterns. Therefore, the new pseudo-code goes as the follow. 

\begin{algorithm}[H]
\caption{New-Plan-Query($U$)}\label{alg:greedy}
\begin{algorithmic}

\State $P \leftarrow []$, $B\leftarrow \emptyset$
\While{$U\neq \emptyset$}
\State $t_{best}\leftarrow \perp$, $score_{beset} \leftarrow 100$, intersected $\leftarrow$ false
\For{\textbf{each} unprocessed tripple pattern $t\in U$}
\State $score \leftarrow$ the position of $t$ in $\prec$ where the variables in $B$ are considered bounded
\If{$t_{best} = \perp$}
\State intersected = ($var(t) \cap B \neq \emptyset$)
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$
\ElsIf{intersected}
\If{$score < score_{best}$ and either $var(t) = \emptyset$ or $var(t) \cap B \neq \emptyset$}
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$
\EndIf
\Else
\If{$var(t) = \emptyset$ or $var(t) \cap B \neq \emptyset$} \Comment{Make sure that the next pattern share some variables.}
\State $t_{best} \leftarrow t$, $score_{best} \leftarrow score$, intersected $\leftarrow$ true
\EndIf
\EndIf

\EndFor
\EndWhile

\end{algorithmic}
\end{algorithm}

In the new query plan, still, we take the first unprocessed triple pattern as our best plan at the beginning. However, we will mark down if the first pattern shares some common variables with some processed patterns. If it is, we will select the least selectivity pattern that also share some common variables in the remaining as in the model answer. However, if the first triple pattern does not share any processed variable, we pick the first pattern that shares some processed variables and then we search for the least selectivity pattern as before. The new plan in the example will now become $\langle X, 1, 2\rangle \mapsto \langle X, 4, Y\rangle \mapsto \langle Y, 2, 3\rangle$. 

I also did some experiments showing that the strategy works. The testing protocol is the same as the one in the question 3. From the table 1, we see that there is a significant improvement for query 2, 7, 8, and 9. 

\begin{table}[]\centering
\begin{tabular}{|l|l|l|}
\hline
    & Model Answer & New Query Plan \\ \hline
q1  & 7            & 8              \\ \hline
q2  & 10107        & 22             \\ \hline
q3  & 24           & 25             \\ \hline
q4  & 2            & 2              \\ \hline
q5  & 37           & 37             \\ \hline
q6  & 25           & 25             \\ \hline
q7  & 64267        & 133            \\ \hline
q8  & 801          & 128            \\ \hline
q9  & 46215        & 250            \\ \hline
q10 & 31           & 29             \\ \hline
q11 & 1            & 1              \\ \hline
q12 & 0            & 0              \\ \hline
q13 & 33           & 35             \\ \hline
q14 & 19           & 18             \\ \hline
\end{tabular}
\caption{Time took to process and evaluate the query by the model answer and the new query plan in ms on the data set LUBM-001-mat.ttl.}
\end{table}
\item The component for parsing and importing Turtle files.

This part is included in Turtle\_handler.cpp. The error checking increases the running time by a lot. 

\item The parser for SPARQL queries

This part is included in query\_parser.cpp. My parser not only reads the query but also checks if the triple patterns are correct such as if the query is asking for something that is not presented in the database, it will throw a warning right away instead of feeding it into the query engine to create overhead. 

\item The component implementing the command line

This part is included in interface.cpp.

\end{enumerate}

\item[3.a]
\begin{enumerate}
\item 

Hardware and Software Configuration:

\begin{enumerate}
\item Model Identifier:	MacBookPro14,3

\item Processor Name:	Quad-Core Intel Core i7

\item Processor Speed:	2.9 GHz

\item Number of Processors:	1

\item Total Number of Cores:	4

\item L2 Cache (per Core):	256 KB

\item L3 Cache:	8 MB

\item Memory:	16 GB

\item Operating System: macOS Big Surf, Version 11.6 (20G165)

\item Compiler Version: Apple clang version 11.0.0 (clang-1100.0.33.8)

\end{enumerate}

\item 

We set a timeout if one instruction takes more than 3 minutes. 

Loading Data Test Protocol:

\begin{enumerate}
\item Turn off all irrelevant applications.
\item Start a clean terminal.
\item Make all and run the output file.
\item Load one dataset and markdown the time. If timeout, mark TO. 
\item Go back to step two repeat this process for 10 times.
\item Take off the highest and the lowest and find the average. 
\end{enumerate}

\item 

Loading Data Test Protocol:

We choose COUNT instead of SELECT and for each query. Still, we set a timeout if one instruction takes more than 3 minutes. 

\begin{enumerate}
\item Turn off all irrelevant applications.
\item Start a clean terminal.
\item Make all and run the output file.
\item Load one dataset. 
\item Run a query and markdown the time. 
\item Go back to the last step repeat this process for 10 times. 
\item Take off the highest and the lowest and find the average. 


\end{enumerate}


\end{enumerate}

\item[3.b] The time needed to load and index the data and the time needed to produce all query answers for each RDF graph and query are showed in table 2 and table 3, respectively.

\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|}
\hline
                   & LUBM-001-mat & LUBM-010-mat & LUBM-100-mat \\ \hline
Load \& Index Time & 902         & 11879        & 122583       \\ \hline
\end{tabular}
\caption{Time needed to load and index the data in ms.}
\end{table}



\begin{table}[H]\centering
\begin{tabular}{|l|l|l|l|}
\hline
    & LUBM-001-mat & LUBM-010-mat & LUBM-100-mat \\ \hline
q1  & 4.081        & 42.336       & 502.755      \\ \hline
q2  & 22.829       & 237.585      & 2438.57      \\ \hline
q3  & 12.408       & 131.304      & 1425.94      \\ \hline
q4  & 1.573        & 10.439       & 132.892      \\ \hline
q5  & 17.797       & 178.091      & 1935.87      \\ \hline
q6  & 8.212        & 108.531      & 1044.5       \\ \hline
q7  & 90.213       & 974.828      & 10386.4      \\ \hline
q8  & 70.124       & 673.855      & 6589.79      \\ \hline
q9  & 71.726       & 723.767      & 7494.22      \\ \hline
q10 & 15.919       & 182.715      & 1907.54      \\ \hline
q11 & 0.941        & 6.773        & 63.929       \\ \hline
q12 & 0.259        & 1.833        & 18.833       \\ \hline
q13 & 16.587       & 200.297      & 2066.33      \\ \hline
q14 & 7.325        & 94.932       & 814.723      \\ \hline
\end{tabular}
\caption{Time needed to produce  all query answers in ms.}
\end{table}

\item[3.c]
\begin{enumerate}
\item[q1:] This query consists of two triple patterns and they are in the form of $\langle X, p, o\rangle$. Therefore, the algorithm just pick a $X$ in the first pattern and see if the $X$ can be fitted into the second pattern. Therefore, it is quick.

\item[q2:] This query contains two groups, $\langle X, p, o\rangle$ and $\langle X, p, Z\rangle$, and each group has three triples. By my planning, the query is planned in find a $\langle X, p, o\rangle$ and find a $\langle X, p, Z\rangle$ that match the first pick, then pick whatever match the variable, $Z$, in the remaining unprocessed patterns. Therefore, it picks the least selectivity pattern in each step, resulting a very small running time. 
\item[q3:] This one is similar to q1 but the time is different because they are different in size. In LUBM-001-mat.ttl, q3 has 5999 possible match in the first pattern and 6 in the second. However, q1 has 1874 in the first and 4 in the second. 
\item[q4:] Though this query looks terrify, the speed is fast because all patterns share the same $X$ in $p$ and beside this, there is at most one free variable in each. Therefore, once $X$ is picked, the remaining is just to check if $Y$ can go with $X$. Also, the size is small, there are 447 possibility in the first pattern and  41 in the second pattern for  LUBM-001-mat.ttl. 
\item[q5:] This one is similar to q1 and q3 but is much slower, which is because the search space is large. This one has 8330 possibility for the first pattern and  719 for the second. 
\item[q6:] This query simply match just one pattern. No plan is needed. It is slower than q1 because it returns 7790 patterns more than q1, which is just 4. 
\item[q7:] There is nothing wrong with the query plan on a high (selectivity) level  that it chooses the first pattern $\langle X, p, o\rangle$, then $\langle X, p , Y\rangle$, and matches the rest. The plan is perfect if we don't check how large is each triple patterns. There are two patterns like $\langle X, p, o\rangle$; the first one has the size 7790 and the second one is 1627. If we start from the second one, we could speed up by a lot. But we did the first one instead because it is the order it comes in and we didn't track the size of each index map to make adjustment.
\item[q8:] q8 has one more free variable than q7 and has 7790 results for LUBM-001-mat.ttl. Beside this, the query plan did perfectly and the time is considerably reasonable.
\item[q9:] q9 has the same complexity as q8. The query plan is still match $\langle X, p, o\rangle$ and find $\langle X, p, Y\rangle$, and it is perfect in a high level sense. Possibly, if we choose a different start ($?X$, $?Y$, $?Z$, in the first, second, and third pattern), we might have a different timing because the size of them are different. However, like q7, we did not track the size of the index map, so we don't know. 
\item[q10:] Same as q1 and q3. It is slightly slower because of larger cordiality in each triple pattern.
\item[q11:] Like q10. It is faster because it only needs to check 223 * 239 elements for  LUBM-001-mat.ttl. 
\item[q12:] It is super fast because the query plan is perfect and the size is small. It first takes $\langle X, p, o\rangle$, then $\langle X, p, Y\rangle$, and then all other are just $\langle s, p, o\rangle$ and can be verified very quickly.
\item[q13:]  Because of the selectivity, the plan first do the first pattern and then the second. There are 8330 chooses for the first pattern but just one for the second. If we do the second one first, it will be quick. But again, we don't know this ahead and the first pattern has lower selectivity. 
\item[q14:] This one is just like q6, but from another direction. It needs to traverse 5916 elements for LUBM-001-mat.ttl, which is smaller than q6, so it is quicker. Fair enough. 
\end{enumerate}

\end{enumerate}
















\end{document}